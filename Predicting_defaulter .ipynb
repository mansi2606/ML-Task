{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting_defaulter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN-FwFta0sf0"
      },
      "source": [
        "# Problem Statement Outline\n",
        "### About the Data\n",
        "* NPAs (Non Performing Assets) have reached all time high\n",
        "* Itâ€™s stock has fallen by 20% in the previous quarter alone\n",
        "* Majority of NPA was contributed by loan defaulters.\n",
        "* along with the bank, the investors perform due diligence on the requested loan application. \n",
        "\n",
        "\n",
        "##use machine learning to figure out a way to find these defaulters and devise a plan to reduce them.\n",
        "##In this challenge, you will help this bank by predicting the probability that a member will default.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYp6FU-s3IGa"
      },
      "source": [
        "* Evaluation based on AUC-ROC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_tMB8hdw9n"
      },
      "source": [
        "!unzip /content/drive/MyDrive/dataset.zip -d /content/drive/MyDrive/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27sKqL2lg9I0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDzfcV1p5TUL"
      },
      "source": [
        "#About the Data\n",
        "* **member_id**  unique ID assigned to each member\n",
        "* **loan_amnt**\tloan amount applied by the member\n",
        "* **funded_amnt**\tloan amout  sanctioned by the bank\n",
        "* **funded_amnt_inv**\tloan amount  sanctioned by the investors\n",
        "* **term**\tterm of loan (in months)\n",
        "* **batch_enrolled**\tbatch numbers allotted to members\n",
        "* **int_rate**\tinterest rate (%) on loan\n",
        "* **grade**\tgrade assigned by the bank\n",
        "* **sub_grade**\tgrade assigned by the bank\n",
        "* **emp_title**\tjob / Employer title of member\n",
        "* **emp_length**\temployment length, where 0 means less than one year and 10 means ten or more years\n",
        "* **home_ownership**\tstatus of home ownership\n",
        "* **annual_inc**\tannual income ($) reported by the member\n",
        "* **verification_status**\tstatus of income verified by the bank\n",
        "* **pymnt_plan**\tindicates if any payment plan has started against loan\n",
        "* **desc**\tloan description provided by member\n",
        "* **purpose**\tpurpose of loan\n",
        "* **title**\tloan title provided by member\n",
        "* **zip_code**\tfirst three digits of area zipcode of member\n",
        "\n",
        "* **addr_state**\tliving state of member\n",
        "* **dti**\tratio of member's total monthly debt repayment excluding mortgage divided by self reported monthly income\n",
        "* **delinq_2yrs**\tnumber of 30+ days delinquency in past 2 years\n",
        "* **inq_last_6mths**\tnumber of inquiries in last 6 months\n",
        "* **mths_since_last_delinq**\tnumber of months since last delinq\n",
        "* **mths_since_last_record**\tnumber of months since last public record\n",
        "* **open_acc**\tnumber of open credit line in member's credit line\n",
        "* **pub_rec**\tnumber of derogatory public records\n",
        "* **revol_bal**\ttotal credit revolving balance\n",
        "* **revol_util**\tamount of credit a member is using relative to revol_bal\n",
        "* **total_acc**\ttotal number of credit lines available in members credit line\n",
        "* **initial_list_status**\tunique listing status of the loan - W(Waiting), F(Forwarded)\n",
        "* **total_rec_int**\tinterest received till date\n",
        "* **total_rec_late_fee**\tLate fee received till date\n",
        "* **recoveries**\tpost charge off gross recovery\n",
        "* **collection_recovery_fee**\tpost charge off collection fee\n",
        "\n",
        "* **collections_12_mths_ex_med**\tnumber of collections in last 12 months excluding medical collections\n",
        "* **mths_since_last_major_derog**\tmonths since most recent 90 day or worse rating\n",
        "* **application_type**\tindicates when the member is an individual or joint\n",
        "* **verification_status_joint**\tindicates if the joint members income was verified by the bank\n",
        "* **last_week_pay**\tindicates how long (in weeks) a member has paid EMI after batch enrolled\n",
        "* **acc_now_delinq**\tnumber of accounts on which the member is delinquent\n",
        "* **tot_coll_amt**\ttotal collection amount ever owed\n",
        "* **tot_cur_bal**\ttotal current balance of all accounts\n",
        "* **total_rev_hi_lim**\ttotal revolving credit limit\n",
        "* **loan_status**\tstatus of loan amount, 1 = Defaulter, 0 = Non Defaulters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hkAN1uihGY0"
      },
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/data/ML_Artivatic_dataset/train_indessa.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/data/ML_Artivatic_dataset/test_indessa.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4v1F8ZsA-wN"
      },
      "source": [
        "print('data',data.shape)\n",
        "print('test',test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za7b5f0yh4dZ"
      },
      "source": [
        "#finding null values \n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl19TMbXU3mh"
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fls_WJYk_Ohw"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHz43G9x5S9A"
      },
      "source": [
        "data.describe(include=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2pxGfRB2co_"
      },
      "source": [
        "##Let's get a report of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHP50xv22a7W"
      },
      "source": [
        "!pip install pandas-profiling[notebook,html]\n",
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(train, title='Report0')\n",
        "profile.to_file('your_report.html')#saves a html page with the overview of the data when running on your local machine."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCSzqNxIfOok"
      },
      "source": [
        "Let's observe defaulter and try to observe the pattern towards becoming a defaulter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoum1hRMXm3T"
      },
      "source": [
        "sns.swarmplot(x=data['loan_status'], y=data['annual_inc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmJ_OAS44Dee"
      },
      "source": [
        "sns.lineplot(x=data['dti'],y=data['loan_status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAuRq6coaDJz"
      },
      "source": [
        "sns.barplot(x=data['funded_amnt'], y=data['term'],hue=data['loan_status'],ci=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPy92w9B5lYS"
      },
      "source": [
        "**For a larger amount of loan, a longer term of repayment is preferred by clients. But increasing the term or giving a lesser amount makes no big differencce in the person's being defaulter.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bPexTiaa5Xj"
      },
      "source": [
        "sns.lineplot(x=data['funded_amnt'], y=data['int_rate'],hue=data['loan_status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5w87tbD7FAX"
      },
      "source": [
        "**For a larger amount of loan and when the interest rate is higher people are more people towards defaultors can be observed.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn8_ztizd4fj"
      },
      "source": [
        "sns.barplot(x=data['loan_status'], y=data['revol_bal'],ci=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXSPYrXb_VdJ"
      },
      "source": [
        "**Clients that are regular with their payments have a hight credit revolving balance.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn1Y8diFg0qV"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "sns.barplot(ax=ax,x=data['loan_status'], y=data['addr_state'],ci=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0TLb-X-jM1p"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "sns.countplot(x=data['addr_state'],hue=data['loan_status'],saturation=0.75,ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUig1z-jt9Kl"
      },
      "source": [
        "# fig, ax = plt.subplots(figsize=(20,10/))\n",
        "sns.barplot(x=data['verification_status'],y=data['loan_status'],ci=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQefAXIKDHhZ"
      },
      "source": [
        "data1 = data.groupby('verification_status')['loan_status'].sum()\n",
        "data1.plot.pie(autopct=\"%.1f%%\", pctdistance=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ldPgUBDZ8v"
      },
      "source": [
        "* The bank has a large number of clients that are not verified before sanctioning of a loan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZypPf2Jt0h1"
      },
      "source": [
        "new=data.groupby('verification_status')['loan_status']\n",
        "new.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pe0EXn_Ebs3"
      },
      "source": [
        "* This shows that clients that are not verified are more likely to be \n",
        "defaulters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuMK3n0m3epB"
      },
      "source": [
        "#Missing Value Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8is1uCXB3kSL"
      },
      "source": [
        "###Dropping Columns and Rows\n",
        "threshold = 50\n",
        "#Dropping columns with missing value rate higher than threshold\n",
        "cols = data.columns[(100 * data.isnull().sum() / len(data)).round(2) > threshold]\n",
        "data.drop(columns=cols,inplace=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un9fFPkzQU_z"
      },
      "source": [
        "data.columns[data.isnull().sum()>0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGYASLCiyR_4"
      },
      "source": [
        "#**Imputation using mean**\n",
        "Using a Traditional split, compute and merge trick - To save processing time of DataFrame. Can also be done with some new alogs - yet takes time to set the system configurations. So, sticking traditional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotkOfKkycVB"
      },
      "source": [
        "data = data.sample(frac=1)\n",
        "\n",
        "data_split_1 = data[:100000]\n",
        "data_split_2 = data[100000:200000]\n",
        "data_split_3 = data[200000:300000]\n",
        "data_split_4 = data[300000:400000]\n",
        "data_split_5 = data[400000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZHFpVNEykba"
      },
      "source": [
        "data_split_1.fillna(data_split_1.mean(), inplace=True)\n",
        "data_split_2.fillna(data_split_2.mean(), inplace=True)\n",
        "data_split_3.fillna(data_split_3.mean(), inplace=True)\n",
        "data_split_4.fillna(data_split_4.mean(), inplace=True)\n",
        "data_split_5.fillna(data_split_5.mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbFD_PeGn_lj"
      },
      "source": [
        "print(data_split_1.shape)\n",
        "print(data_split_2.shape)\n",
        "print(data_split_3.shape)\n",
        "print(data_split_4.shape)\n",
        "print(data_split_5.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQeX5uzQoCWr"
      },
      "source": [
        "#Merging the splitted dataframes to an aggreagated dataframe\n",
        "data = pd.concat([data_split_1, data_split_2, data_split_3, data_split_4, data_split_5], ignore_index=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C795GTkro0f9"
      },
      "source": [
        "#Dropping rows with Missing values - rows that are not feasible for imputation\n",
        "data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrSOqBnP63Uf"
      },
      "source": [
        "#Corelation  Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATrCtyEYb-v9"
      },
      "source": [
        "def remove_collinear_features(x, threshold):\n",
        "    \n",
        "    # Dont want to remove correlations between loan_status\n",
        "    y = x['loan_status']\n",
        "    x = x.drop(columns = ['loan_status'])\n",
        "    \n",
        "    # Calculate the correlation matrix\n",
        "    corr_matrix = x.corr()\n",
        "    iters = range(len(corr_matrix.columns) - 1)\n",
        "    drop_cols = []\n",
        "\n",
        "    # Iterate through the correlation matrix and compare correlations\n",
        "    for i in iters:\n",
        "        for j in range(i):\n",
        "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
        "            col = item.columns\n",
        "            row = item.index\n",
        "            val = abs(item.values)\n",
        "            \n",
        "            # If correlation exceeds the threshold\n",
        "            if val >= threshold:\n",
        "                # Print the correlated features and the correlation value\n",
        "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
        "                drop_cols.append(col.values[0])\n",
        "\n",
        "    # Drop one of each pair of correlated columns\n",
        "    drops = set(drop_cols)\n",
        "    x = x.drop(columns = drops)\n",
        "    \n",
        "    # Add the score back to the data\n",
        "    x['loan_status'] = y\n",
        "               \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkLgks2aBqoU"
      },
      "source": [
        "data=remove_collinear_features(data,0.6)\n",
        "test_cols=data.columns #gathering columns for test data preparation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u4LptZj65QP"
      },
      "source": [
        "#Correlations between Features and Target\n",
        "\n",
        "#Find all correlations and sort\n",
        "correlations_df = data.corr()['loan_status'].sort_values()\n",
        "\n",
        "# #Print the most negative correlations\n",
        "print(correlations_df.head(15), '\\n')\n",
        "\n",
        "# #Print the most positive correlations\n",
        "print(correlations_df.tail(15))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouBoUYzAnsfv"
      },
      "source": [
        "fig,ax=plt.subplots(figsize=(20,20))\n",
        "correlation = data.corr()\n",
        "sns.heatmap(correlation,xticklabels=True,yticklabels=True,ax=ax,annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf1IvHzBfrHN"
      },
      "source": [
        "##**2. Outlier analysis**\n",
        "We will plot a boxplot to observe the outliers in our data and clean the outliers for training as well as testing dat to avoid any kind of extreme variance in our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qgcVo50_DSs"
      },
      "source": [
        "# data.boxplot(figsize=(30,15))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EefMZ_0MaC5w"
      },
      "source": [
        "# cols = data.select_dtypes(include=[np.float]).columns\n",
        "# for n in cols:\n",
        "#   q1=data[n].quantile(.25)\n",
        "#   q3=data[n].quantile(.75)\n",
        "#   iqr=q3-q1\n",
        "#   data[n]=np.clip(data[n],q1-1.5*iqr,q3+1.5*iqr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCso4vym9I28"
      },
      "source": [
        "#**Split in training and testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKOHk7jaXBR"
      },
      "source": [
        "#splitting the given data in training and test to check on knowm\n",
        "new = data.select_dtypes(include=[np.object]).columns\n",
        "thres=10\n",
        "for n in new:\n",
        "  if (data[n].nunique()) < thres:\n",
        "    data = pd.get_dummies(data,columns=[n],drop_first=True)\n",
        "\n",
        "\n",
        "data.drop(columns=(data.select_dtypes(include=[np.object]).columns),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGfKb_9R6_AG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Separate out the features and targets\n",
        "features = data.drop(columns='loan_status')\n",
        "targets = pd.DataFrame(data['loan_status'])\n",
        "\n",
        "#Split into 80% training and 20% testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy1AxtSg9V_T"
      },
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaftXwcR9Yn9"
      },
      "source": [
        "#Convert y to one-dimensional array (vector)\n",
        "y_train = np.array(y_train).reshape((-1, ))\n",
        "y_test = np.array(y_test).reshape((-1, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2IHsgKTEZVG"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "#metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix,r2_score,mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zcO9VCXx5sI"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6c_ZP76Ktsf"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(C=0.4,max_iter=1000,solver='liblinear')\n",
        "classifier.fit(X_train,y_train)\n",
        "y_pred_lr = classifier.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_lr)\n",
        "prec = precision_score(y_test, y_pred_lr,average='weighted')\n",
        "rec = recall_score(y_test, y_pred_lr,average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, y_pred_lr)\n",
        "results = pd.DataFrame([['Logistic Regression', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "# results = results.append(model_results, ignore_index = True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnR_nvbvy1mA"
      },
      "source": [
        "#Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsjGv7DVK1ef"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=14) \n",
        "# training the classifier\n",
        "clf.fit(X_train,y_train)\n",
        "# do our predictions on the test\n",
        "pred_dt = clf.predict(X_test)\n",
        "# Predicting Test Set\n",
        "\n",
        "acc = accuracy_score(y_test, pred_dt)\n",
        "prec = precision_score(y_test, pred_dt,average='weighted')\n",
        "rec = recall_score(y_test, pred_dt,average='weighted')\n",
        "f1 = f1_score(y_test, pred_dt, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, pred_dt)\n",
        "model_results = pd.DataFrame([['Decision Tree', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GGyOVmzy5mK"
      },
      "source": [
        "#Random Forest Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXayB6rQLFh-"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(X_train,y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred_rf = clf_rf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred_rf)\n",
        "prec = precision_score(y_test, y_pred_rf,average='weighted')\n",
        "rec = recall_score(y_test, y_pred_rf,average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, y_pred_rf)\n",
        "model_results = pd.DataFrame([['Random forest classifier', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BRLICjdxqax"
      },
      "source": [
        "#Ada Boost with RFC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqN9517RLzjS"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf=RandomForestClassifier()\n",
        "abc = AdaBoostClassifier(base_estimator=clf,n_estimators=50,learning_rate=1)\n",
        "# Train Adaboost Classifer\n",
        "model = abc.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_abc = model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_abc)\n",
        "prec = precision_score(y_test, y_pred_abc,average='weighted')\n",
        "rec = recall_score(y_test, y_pred_abc,average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_abc, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, y_pred_abc)\n",
        "model_results = pd.DataFrame([['Adaboost ', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jUpoN_DVYr_"
      },
      "source": [
        "#XG Boost\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bj1w7_JMSd6"
      },
      "source": [
        "import xgboost as xgb\n",
        "model =xgb.XGBClassifier(learning_rate=0.06,colsample_bytree = 0.6, subsample = 0.8,n_estimators=200,max_depth=3, gamma=0)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred_xg = model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_xg)\n",
        "prec = precision_score(y_test, y_pred_xg,average='weighted')\n",
        "rec = recall_score(y_test, y_pred_xg,average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_xg, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, y_pred_xg)\n",
        "model_results = pd.DataFrame([['XG Boost', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ZFp5rwGlFO"
      },
      "source": [
        "#Bernoullie Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJvN6kvyMxB6"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "model_bnb = BernoulliNB()\n",
        "model_bnb.fit(X_train,y_train)\n",
        "# Predicting Test Set\n",
        "pred_bnb = model_bnb.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, pred_bnb)\n",
        "prec = precision_score(y_test, pred_bnb,average='weighted')\n",
        "rec = recall_score(y_test, pred_bnb,average='weighted')\n",
        "f1 = f1_score(y_test, pred_bnb, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, pred_bnb)\n",
        "model_results = pd.DataFrame([['Bernouillie Naive Bayes', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCMEMX41M2Ly"
      },
      "source": [
        "result=pd.DataFrame(results)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS0R-1egKrzd"
      },
      "source": [
        "#Best Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH3AWhulM8Ko"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "max_acc_index=results.Accuracy[results.Accuracy==results.Accuracy.max()].index[0]\n",
        "plt.barh(results.Model,results.Accuracy,color='c')\n",
        "plt.barh(results.Model[max_acc_index],results.Accuracy[max_acc_index],color='m')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGbAteF7G88K"
      },
      "source": [
        "#Best Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLCNcc-GNAWl"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "max_pre_index=results.Precision[results.Precision==results.Precision.max()].index[0]\n",
        "plt.barh(results.Model,results.Precision,color='c')\n",
        "plt.barh(results.Model[max_pre_index],results.Precision[max_pre_index],color='m')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tte85oxHCnX"
      },
      "source": [
        "#Best Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G70XNUYPNGCa"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "max_rc_index=results.Recall[results.Recall==results.Recall.max()].index[0]\n",
        "plt.barh(results.Model,results.Recall,color='c')\n",
        "plt.barh(results.Model[max_rc_index],results.Recall[max_rc_index],color='m')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zRmCT-OHHi2"
      },
      "source": [
        "#best F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFlTnemCNKZs"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "max_f1_index=results['F1 Score'][results['F1 Score']==results['F1 Score'].max()].index[0]\n",
        "plt.barh(results.Model,results['F1 Score'],color='c')\n",
        "plt.barh(results.Model[max_f1_index],results.Accuracy[max_f1_index],color='m')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_93TGNLc5dv"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "max_f1_index=results['ROC_AUC'][results['ROC_AUC']==results['ROC_AUC'].max()].index[0]\n",
        "plt.barh(results.Model,results['ROC_AUC'],color='c')\n",
        "plt.barh(results.Model[max_f1_index],results.Accuracy[max_f1_index],color='m')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGyMpKwYUD8-"
      },
      "source": [
        "#Checking on the actual test data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI6vL27VUlPf"
      },
      "source": [
        "###Missing Value Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Z2scADU62w"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2LLXFcKjDP2"
      },
      "source": [
        "#including the same columns from the train data after eliminating the missing value columns\n",
        "test=test[['member_id', 'loan_amnt', 'funded_amnt', 'term', 'batch_enrolled',\n",
        "       'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
        "       'home_ownership', 'annual_inc', 'verification_status', 'pymnt_plan',\n",
        "       'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
        "       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',\n",
        "       'initial_list_status', 'total_rec_int', 'total_rec_late_fee',\n",
        "       'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med',\n",
        "       'application_type', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt',\n",
        "       'tot_cur_bal']]\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOv4gUFeVCGr"
      },
      "source": [
        "#splittting the test data to fill NAN values\n",
        "\n",
        "test = test.sample(frac=1)\n",
        "test_split_1 = test[:100000]\n",
        "test_split_2 = test[100000:200000]\n",
        "test_split_3 = test[200000:300000]\n",
        "test_split_4 = test[300000:]\n",
        "# data_split_5 = data[400000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTB1pECVhSy"
      },
      "source": [
        "test_split_1.fillna(test_split_1.mean(), inplace=True)\n",
        "test_split_2.fillna(test_split_2.mean(), inplace=True)\n",
        "test_split_3.fillna(test_split_3.mean(), inplace=True)\n",
        "test_split_4.fillna(test_split_4.mean(), inplace=True)\n",
        "# data_split_5.fillna(data_split_5.mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXWfREfrVhGK"
      },
      "source": [
        "test = pd.concat([test_split_1, test_split_2, test_split_3, test_split_4], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqePyJxkVhAg"
      },
      "source": [
        "#Dropping rows with Missing values - rows that are not feasible for imputation\n",
        "test.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OozftDf1Vt94"
      },
      "source": [
        "#Outlier Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRNhZqWIV_ge"
      },
      "source": [
        "# cols = data.select_dtypes(include=[np.float]).columns\n",
        "# for n in cols:\n",
        "#   q1=data[n].quantile(.25)\n",
        "#   q3=data[n].quantile(.75)\n",
        "#   iqr=q3-q1\n",
        "#   data[n]=np.clip(data[n],q1-1.5*iqr,q3+1.5*iqr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbxqYCx3ebCL"
      },
      "source": [
        "CHecking categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6NGJsRedkJ"
      },
      "source": [
        "new = test.select_dtypes(include=[np.object]).columns\n",
        "thres=10\n",
        "for n in new:\n",
        "  if (test[n].nunique()) < thres:\n",
        "    test = pd.get_dummies(test,columns=[n],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c2HKUMgrLxs"
      },
      "source": [
        "test.drop(columns=(test.select_dtypes(include=[np.object]).columns),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_XjjE-rN0c"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlI-gFsHem5u"
      },
      "source": [
        "Scaling our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzXoHXfsepmX"
      },
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "# _train = sc.fit_transform(X_train)\n",
        "x_test = sc.fit_transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys9IwEEsfZhN"
      },
      "source": [
        "#y_test=test['loan_status'] for prediction \n",
        "y_test = np.array(y_test).reshape((-1, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXhvq2c3WBxJ"
      },
      "source": [
        "#Let's fit our data and use two models with best scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58BYxwGCd9qA"
      },
      "source": [
        "RANDOM FOREST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-zxs0TkeBEL"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(X_train,y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred_rf = clf_rf.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_pred_rf)\n",
        "prec = precision_score(y_test, y_pred_rf,average='weighted')\n",
        "rec = recall_score(y_test, y_pred_rf,average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, y_pred_rf)\n",
        "model_results = pd.DataFrame([['Random forest classifier', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_rf)\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve - Gradient Boosting Classification')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrO9FLGmeLQX"
      },
      "source": [
        "DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhqhUvC-eNNM"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=14) \n",
        "# training the classifier\n",
        "clf.fit(X_train,y_train)\n",
        "# do our predictions on the test\n",
        "pred_dt = clf.predict(X_test)\n",
        "# Predicting Test Set\n",
        "\n",
        "acc = accuracy_score(y_test, pred_dt)\n",
        "prec = precision_score(y_test, pred_dt,average='weighted')\n",
        "rec = recall_score(y_test, pred_dt,average='weighted')\n",
        "f1 = f1_score(y_test, pred_dt, average='weighted')\n",
        "roc_auc= roc_auc_score(y_test, pred_dt)\n",
        "model_results = pd.DataFrame([['Decision Tree', acc,prec, rec, f1,roc_auc]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision','Recall', 'F1 Score','ROC_AUC'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "print(results)\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, pred_dt)\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve - Gradient Boosting Classification')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP_7nX_Kcdmw"
      },
      "source": [
        "**Since Decision Tree Classifier has a better ROC score, using it's prediction for submission file**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZBz2tHNiUgQ"
      },
      "source": [
        "#Getting the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBkP_vDviYEg"
      },
      "source": [
        "submission=pd.DataFrame(data=[test['member_id'],pred_dt],columns=['member_id','Predictions'],index=None)\n",
        "submission.to_csv('/Submission.csv')\n",
        "                        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}